<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>DataPlatform Franchising</title><link href="http://datapfranc.github.io/" rel="alternate"></link><link href="http://datapfranc.github.io/feeds/martin-ouellet.atom.xml" rel="self"></link><id>http://datapfranc.github.io/</id><updated>2016-07-07T17:12:00+02:00</updated><entry><title>Loading into Redshift</title><link href="http://datapfranc.github.io/misc/brd_loading_rs/" rel="alternate"></link><published>2016-07-07T17:12:00+02:00</published><author><name>Martin Ouellet</name></author><id>tag:datapfranc.github.io,2016-07-07:misc/brd_loading_rs/</id><summary type="html">&lt;!-- Status: draft --&gt;
&lt;p&gt;This post will go through the steps needed to set-up a new Redshift cluster and get data into it.  We'll be using a standard approach but there are many  alternatives, see &lt;a href="http://thelink"&gt;here&lt;/a&gt; for more details.  For the sake of simplicity, we assume a number of ETL jobs already exist to generate the presentation-layer data as flat files.  In real life, these ETL jobs would hold and maintain our set of Business rules and transformation logic required by our project, but for now we only focus on loading mechanisms involved with Redshift.&lt;/p&gt;
&lt;h3 id="setting-up-an-amazon-redshift-cluster"&gt;Setting up an Amazon Redshift Cluster&lt;/h3&gt;
&lt;p&gt;The pre-requisite ...&lt;/p&gt;&lt;/!--&gt;</summary><category term="dataset"></category><category term="redshift"></category></entry><entry><title>BRD summary stats</title><link href="http://datapfranc.github.io/misc/brd_basicstat/" rel="alternate"></link><published>2016-06-28T14:47:00+02:00</published><author><name>Martin Ouellet</name></author><id>tag:datapfranc.github.io,2016-06-28:misc/brd_basicstat/</id><summary type="html">&lt;p&gt;After a few weeks spent harvesting and integrating book reviews, it is time to share some statistics.  &lt;/p&gt;
&lt;p&gt;Over &lt;strong&gt;22 millions&lt;/strong&gt; reviews have been harvested on a sample of roughly 300K books (I use the term Book here instead of Work).  I've started harvesting book sequentially (by id) and later processed them by popularity as a way to get more reviews.  Some Book catalogued in Librarything could not be found in other sites while others had no reviews.&lt;/p&gt;
&lt;table class="table table-hover table-striped"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Statistics&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Librarything&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Goodreads&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Babelio&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Book sample size&lt;/td&gt;
&lt;td&gt;300K&lt;/td&gt;
&lt;td&gt;--&lt;/td&gt;
&lt;td&gt;--&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Book found&lt;/td&gt;
&lt;td&gt;--&lt;/td&gt;
&lt;td&gt;216K&lt;/td&gt;
&lt;td&gt;78K&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Number of reviews&lt;/td&gt;
&lt;td&gt;1.2M&lt;/td&gt;
&lt;td&gt;20.5M&lt;/td&gt;
&lt;td&gt;415K&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Notes on ...&lt;/p&gt;</summary><category term="BRD"></category><category term="dataset"></category></entry><entry><title>BRD Presentation layer</title><link href="http://datapfranc.github.io/misc/brd_pl_intro/" rel="alternate"></link><published>2016-06-22T13:35:00+02:00</published><author><name>Martin Ouellet</name></author><id>tag:datapfranc.github.io,2016-06-22:misc/brd_pl_intro/</id><summary type="html">&lt;p&gt;The Presentation layer's role is to respond to all user needs for reporting, data analytics and front-end applications like visualization or dashboarding. The focus is to optimize read-access, as opposed to write-access. The challenge is to optimize read-access without knowing the exact data access pattern that will be triggered from users interactions.&lt;/p&gt;
&lt;p&gt;In this post, I'll define the physical data model created for a &lt;a href="http://amazon.com/redshift"&gt;Redshift&lt;/a&gt; DWH Cloud target platform.  This implementation choice influences considerably the resulting physical data model.&lt;/p&gt;
&lt;h3 id="redshift"&gt;Redshift&lt;/h3&gt;
&lt;p&gt;Redshift is a Massively parallel processing (MPP) Cloud-based database suited for BI and analytics needs running on top ...&lt;/p&gt;</summary><category term="dataset"></category></entry><entry><title>How to do data integration, BRD example (part3)</title><link href="http://datapfranc.github.io/misc/brd_di_part3/" rel="alternate"></link><published>2016-06-02T09:07:00+02:00</published><author><name>Martin Ouellet</name></author><id>tag:datapfranc.github.io,2016-06-02:misc/brd_di_part3/</id><summary type="html">&lt;h2 id="business-layer"&gt;Business Layer&lt;/h2&gt;
&lt;p&gt;This layer contains derived data needed by Presentation/Delivery layer. We can build components like associations, groupings or hierarchies defined by Business Rules, and also do data cleansing to fix issues found in our &lt;em&gt;raw data&lt;/em&gt;.  &lt;/p&gt;
&lt;h3 id="building-new-association-similar-reviews"&gt;Building new association: Similar Reviews&lt;/h3&gt;
&lt;p&gt;Let's say we're required to find similar reviews written on Work. This could be useful for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Identify duplication issues&lt;/li&gt;
&lt;li&gt;Identify users duplicating reviews within or across sites&lt;/li&gt;
&lt;li&gt;Identify spam where reviews are written to bias opinion&lt;/li&gt;
&lt;li&gt;Find plagiarism among reviewers&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;How do we do that?  Data processing on unstructured text is efficiently done using NoSQL ...&lt;/p&gt;</summary><category term="BRD"></category><category term="data integration"></category></entry><entry><title>How to do data integration, BRD example (part2)</title><link href="http://datapfranc.github.io/misc/brd_di_part2/" rel="alternate"></link><published>2016-05-21T11:15:00+02:00</published><author><name>Martin Ouellet</name></author><id>tag:datapfranc.github.io,2016-05-21:misc/brd_di_part2/</id><summary type="html">&lt;h2 id="physical-data-model"&gt;Physical Data model&lt;/h2&gt;
&lt;p&gt;This post presents the physical data model. Compare to &lt;a href="http://datapfranc.github.io/misc/brd_di_part1/"&gt;logical model&lt;/a&gt;, it contains a lot more tables. Relational databases are less flexible than schema-less NoSQL environments and highly normalized model is one technique used to mitigate rigidity through extension. We accommodate changes by adding new structures as we discover new attributes and relationship relevant to our evolving needs. Interested reader can check methods like &lt;a href="https://en.wikipedia.org/wiki/Data_Vault_Modeling"&gt;Data Vault&lt;/a&gt; or &lt;a href="http://www.anchormodeling.com/?page_id=2"&gt;Anchor Modeling&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To explain some details of physical data model, we'll look at the code.  Although SQL is not well suited for self-documented code, most DB engines support explicit ...&lt;/p&gt;</summary><category term="BRD"></category><category term="data integration"></category></entry><entry><title>How to do data integration, BRD example</title><link href="http://datapfranc.github.io/misc/brd_di_part1/" rel="alternate"></link><published>2016-04-01T11:15:00+02:00</published><author><name>Martin Ouellet</name></author><id>tag:datapfranc.github.io,2016-04-01:misc/brd_di_part1/</id><summary type="html">&lt;h3 id="data-integration-one-of-the-main-bi-functions"&gt;Data Integration: one of the main BI functions&lt;/h3&gt;
&lt;p&gt;BI environment architecture is often left as an after-thought. Business is pressuring technical teams for delivery, so they quickly jump into designing star schema or dimensional models (the &lt;strong&gt;Presentation Layer&lt;/strong&gt;), and neglect the &lt;strong&gt;Integration Layer&lt;/strong&gt;.  End result: no separation of concerns will exist between the integration AND presentation aspects.&lt;/p&gt;
&lt;p&gt;Integration and Presentation are critical functions that must be decoupled into separate layers (at least logically) reflecting their independent goals and specifications. Integration is concerned with capturing raw and untransformed data originating from sources, while Presentation applies transformation and business rules to derive ...&lt;/p&gt;</summary><category term="BRD"></category><category term="data integration"></category></entry><entry><title>Why Book Review?</title><link href="http://datapfranc.github.io/misc/brd_why/" rel="alternate"></link><published>2016-03-14T11:15:00+01:00</published><author><name>Martin Ouellet</name></author><id>tag:datapfranc.github.io,2016-03-14:misc/brd_why/</id><summary type="html">&lt;!-- Status: draft --&gt;
&lt;h3 id="passion"&gt;Passion&lt;/h3&gt;
&lt;p&gt;To keep on working on any personal project you need (above all) &lt;strong&gt;motivation&lt;/strong&gt;.  Without any constraints or external pressure to work on something, what can help you maintain motivation? Can factors like potential gain, popularity or recognition help? Answer from personal experience: no.. these probably help at beginning, but on the long run they'll leave you unfulfilled.&lt;/p&gt;
&lt;p&gt;So what else can bring you lasting motivation? One word: passion!  Working on stuff compatible with personal interest make your work less like &lt;em&gt;work&lt;/em&gt; and more like &lt;em&gt;leisure&lt;/em&gt;! Personally, I enjoy working on data-oriented projects so I only need to find ...&lt;/p&gt;&lt;/!--&gt;</summary><category term="BRD"></category></entry></feed>